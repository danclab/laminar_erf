{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5561557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lameg.invert import coregister, invert_ebb, load_source_time_series\n",
    "from lameg.laminar import sliding_window_model_comparison\n",
    "from lameg.util import get_fiducial_coords, get_surface_names, get_bigbrain_layer_boundaries\n",
    "from lameg.surf import interpolate_data\n",
    "from lameg.viz import show_surface, color_map\n",
    "import spm_standalone\n",
    "import matlab\n",
    "import h5py\n",
    "from scipy.spatial import cKDTree, KDTree\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e06b4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SUBJECTS_DIR=/home/common/bonaiuto/cued_action_meg/derivatives/processed/fs/\n"
     ]
    }
   ],
   "source": [
    "%env SUBJECTS_DIR=/home/common/bonaiuto/cued_action_meg/derivatives/processed/fs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb347fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_idx(subj_id, surf_dir, hemi, regions, surf):\n",
    "    \"\"\"\n",
    "    Returns the vertex indices from a downsampled surface mesh that correspond \n",
    "    to specified anatomical regions (from FreeSurfer annotations).\n",
    "\n",
    "    Parameters:\n",
    "    - subj_id (str): FreeSurfer subject ID.\n",
    "    - surf_dir (str): Path to directory containing the postprocessed surfaces (e.g., pial.gii).\n",
    "    - hemi (str or None): Hemisphere ('lh', 'rh', or None for both).\n",
    "    - regions (list of str): List of region names to extract from the annotation.\n",
    "    - surf (nib.GiftiImage): Downsampled surface mesh used for laminar inference.\n",
    "\n",
    "    Returns:\n",
    "    - roi_idx (np.ndarray): Array of indices into `surf` corresponding to the selected ROI.\n",
    "    \"\"\"\n",
    "    fs_subjects_dir = os.getenv('SUBJECTS_DIR')\n",
    "    fs_subject_dir = os.path.join(fs_subjects_dir, subj_id)\n",
    "\n",
    "    roi_idx = []\n",
    "    hemis = []\n",
    "    if hemi is None:\n",
    "        hemis.extend(['lh', 'rh'])\n",
    "    else:\n",
    "        hemis.append(hemi)\n",
    "    for hemi in hemis:\n",
    "        pial = nib.load(os.path.join(surf_dir, f'{hemi}.pial.gii'))\n",
    "\n",
    "        annotation = os.path.join(fs_subject_dir, 'label', f'{hemi}.aparc.annot')\n",
    "        label, ctab, names = nib.freesurfer.read_annot(annotation)\n",
    "\n",
    "        name_indices = [names.index(region.encode()) for region in regions]\n",
    "        orig_vts = np.where(np.isin(label, name_indices))[0]\n",
    "\n",
    "        # Find the original vertices closest to the downsampled vertices\n",
    "        kdtree = KDTree(pial.darrays[0].data[orig_vts, :])\n",
    "        # Calculate the percentage of vertices retained\n",
    "        dist, vert_idx = kdtree.query(surf.darrays[0].data, k=1)\n",
    "        hemi_roi_idx = np.where(dist == 0)[0]\n",
    "        roi_idx = np.union1d(roi_idx, hemi_roi_idx)\n",
    "    return roi_idx.astype(int)\n",
    "\n",
    "\n",
    "def get_cortical_thickness(multilayer_mesh, n_layers):\n",
    "    \"\"\"\n",
    "    Estimates cortical thickness at each vertex from a multilayer surface mesh.\n",
    "\n",
    "    Parameters:\n",
    "    - multilayer_mesh (nib.GiftiImage): Combined mesh of all depth layers (equidistant).\n",
    "    - n_layers (int): Total number of cortical depth surfaces in the mesh.\n",
    "\n",
    "    Returns:\n",
    "    - thickness (np.ndarray): Vertex-wise Euclidean distance between layer 1 and layer N.\n",
    "    \"\"\"\n",
    "    verts_per_surf=int(multilayer_mesh.darrays[0].data.shape[0]/n_layers)\n",
    "    thickness=np.sqrt(np.sum((multilayer_mesh.darrays[0].data[:verts_per_surf,:]-multilayer_mesh.darrays[0].data[(n_layers-1)*verts_per_surf:,:])**2,axis=-1))\n",
    "    return thickness\n",
    "\n",
    "\n",
    "def get_lead_field_rmse(gainmat_fname, n_layers, verts_per_surf):\n",
    "    \"\"\"\n",
    "    Computes the RMSE of lead field vectors across cortical depths \n",
    "    relative to the superficial (layer 1) model, for each vertex.\n",
    "\n",
    "    Parameters:\n",
    "    - gainmat_fname (str): Path to HDF5 file containing the gain matrix ('G').\n",
    "    - n_layers (int): Number of cortical depth layers.\n",
    "    - verts_per_surf (int): Number of vertices per layer.\n",
    "\n",
    "    Returns:\n",
    "    - rmse (np.ndarray): RMSE between deep and superficial lead fields per vertex.\n",
    "    \"\"\"\n",
    "    with h5py.File(gainmat_fname,'r') as file:\n",
    "        lf_mat=file['G'][()]\n",
    "        \n",
    "    layer_lf_mat=np.zeros((verts_per_surf, n_layers, lf_mat.shape[1]))\n",
    "    diff_layer_lf_mat=np.zeros((verts_per_surf, n_layers))\n",
    "    for i in range(n_layers):\n",
    "        layer_lf_mat[:,i,:]=lf_mat[i*verts_per_surf:(i+1)*verts_per_surf,:]\n",
    "    for j in range(verts_per_surf):\n",
    "        for i in range(n_layers):\n",
    "            diff_layer_lf_mat[j,i]=np.sqrt(np.mean((layer_lf_mat[j,i,:]-layer_lf_mat[j,0,:])**2))\n",
    "    return diff_layer_lf_mat[:,-1]\n",
    "\n",
    "            \n",
    "def get_orientation(scalp_mesh_fname, multilayer_mesh, pial_ds_mesh, verts_per_surf):\n",
    "    \"\"\"\n",
    "    Computes the alignment between cortical column orientation vectors and \n",
    "    local scalp surface normals for each vertex.\n",
    "\n",
    "    Parameters:\n",
    "    - scalp_mesh_fname (str): Path to scalp surface (GIFTI).\n",
    "    - multilayer_mesh (nib.GiftiImage): Mesh with orientation vectors per vertex.\n",
    "    - pial_ds_mesh (nib.GiftiImage): Downsampled pial mesh for mapping.\n",
    "    - verts_per_surf (int): Number of vertices per cortical surface.\n",
    "\n",
    "    Returns:\n",
    "    - dot_products (np.ndarray): Cosine similarity (abs dot product) between \n",
    "                                 dipole and scalp normals per vertex.\n",
    "\n",
    "    Notes:\n",
    "    - Higher values indicate more radial orientations\n",
    "    \"\"\"\n",
    "    scalp_mesh=nib.load(scalp_mesh_fname)\n",
    "    scalp_vertices = scalp_mesh.darrays[1].data  # Vertex coordinates\n",
    "    scalp_faces = scalp_mesh.darrays[0].data  # Face indices\n",
    "    \n",
    "    pial_ds_vertices = pial_ds_mesh.darrays[0].data  # Vertex coordinates\n",
    "    multilayer_orientations = multilayer_mesh.darrays[2].data  # Orientation vectors\n",
    "    \n",
    "    # Compute surface normals\n",
    "    def compute_normals(vertices, faces):\n",
    "        normals = np.zeros_like(vertices)\n",
    "        for i in range(faces.shape[0]):\n",
    "            v0, v1, v2 = vertices[faces[i]]\n",
    "            # Edge vectors\n",
    "            edge1 = v1 - v0\n",
    "            edge2 = v2 - v0\n",
    "            # Cross product to get normal\n",
    "            normal = np.cross(edge1, edge2)\n",
    "            normal /= np.linalg.norm(normal)  # Normalize the normal\n",
    "            normals[faces[i]] += normal\n",
    "        normals /= np.linalg.norm(normals, axis=1)[:, np.newaxis]  # Normalize all normals\n",
    "        return normals\n",
    "\n",
    "    normals = compute_normals(scalp_vertices, scalp_faces)\n",
    "\n",
    "    # Build a KD-tree for the scalp vertices\n",
    "    tree = cKDTree(scalp_vertices)\n",
    "\n",
    "    # Find the nearest neighbor in the scalp mesh for each vertex in the downsampled cortical mesh\n",
    "    _, indices = tree.query(pial_ds_vertices)\n",
    "\n",
    "    # Compute the dot product between the orientation and the normal vectors\n",
    "    dot_products = np.abs(np.einsum('ij,ij->i', normals[indices], multilayer_orientations[:verts_per_surf,:])) \n",
    "    return dot_products\n",
    "\n",
    "\n",
    "def get_dist_to_scalp(scalp_mesh_fname, pial_ds_mesh):\n",
    "    \"\"\"\n",
    "    Computes the Euclidean distance from each vertex on the cortical surface \n",
    "    to the closest point on the scalp.\n",
    "\n",
    "    Parameters:\n",
    "    - scalp_mesh_fname (str): Path to scalp surface (GIFTI).\n",
    "    - pial_ds_mesh (nib.GiftiImage): Downsampled pial surface.\n",
    "\n",
    "    Returns:\n",
    "    - distances (np.ndarray): Distance (in mm) from cortex to nearest scalp point per vertex.\n",
    "    \"\"\"\n",
    "    scalp_mesh=nib.load(scalp_mesh_fname)\n",
    "    scalp_vertices = scalp_mesh.darrays[1].data  # Vertex coordinates\n",
    "    \n",
    "    pial_ds_vertices = pial_ds_mesh.darrays[0].data  # Vertex coordinates\n",
    "    \n",
    "    # Build a KD-tree for the scalp vertices\n",
    "    tree = cKDTree(scalp_vertices)\n",
    "\n",
    "    # Find the nearest neighbor in the scalp mesh for each vertex in the downsampled cortical mesh\n",
    "    distances, _ = tree.query(pial_ds_vertices)\n",
    "    \n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193839ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects=[\n",
    "    'sub-001',\n",
    "    'sub-002','sub-002','sub-002','sub-002','sub-002','sub-002',\n",
    "    'sub-003','sub-003','sub-003','sub-003',\n",
    "    'sub-004','sub-004','sub-004','sub-004',\n",
    "    'sub-005','sub-005','sub-005','sub-005',\n",
    "    'sub-006','sub-006','sub-006',\n",
    "    'sub-007','sub-007','sub-007','sub-007',\n",
    "    'sub-008','sub-008','sub-008','sub-008','sub-008'\n",
    "]\n",
    "sessions=[\n",
    "    'ses-01',\n",
    "    'ses-01','ses-02','ses-03','ses-04','ses-05','ses-06',\n",
    "    'ses-01','ses-02','ses-03','ses-04',\n",
    "    'ses-01','ses-02','ses-03','ses-04',\n",
    "    'ses-01','ses-02','ses-03','ses-04',\n",
    "    'ses-01','ses-02','ses-03',\n",
    "    'ses-01','ses-02','ses-03','ses-04',\n",
    "    'ses-01','ses-02','ses-03','ses-04','ses-05'    \n",
    "]\n",
    "\n",
    "subjects_file='/home/common/bonaiuto/cued_action_meg/raw/participants.tsv'\n",
    "preproc_data_dir='/home/common/bonaiuto/cued_action_meg/derivatives/processed'\n",
    "base_out_dir='/home/bonaiuto/laminar_erf/output/motor_epoch'\n",
    "\n",
    "spm = spm_standalone.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers=11\n",
    "for subject, session in zip(subjects,sessions):\n",
    "    print(f'{subject}: {session}')\n",
    "    data_dir=os.path.join(preproc_data_dir,subject,session,'spm')\n",
    "    out_dir=os.path.join(base_out_dir,subject,session)\n",
    "    if not os.path.exists(os.path.join(base_out_dir,subject)):\n",
    "        os.mkdir(os.path.join(base_out_dir,subject))\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "        \n",
    "    out_fname = os.path.join(base_out_dir,f'results_{subject}_{session}.npz')\n",
    "    \n",
    "    if not os.path.exists(out_fname):\n",
    "\n",
    "        mri_fname=os.path.join(preproc_data_dir, subject,'t1w.nii')\n",
    "        \n",
    "        subj_surf_dir=os.path.join(preproc_data_dir,subject,'surf')\n",
    "        multilayer_mesh_fname=os.path.join(subj_surf_dir, 'multilayer.11.ds.link_vector.fixed.gii')\n",
    "        multilayer_mesh=nib.load(multilayer_mesh_fname)\n",
    "        verts_per_surf=int(multilayer_mesh.darrays[0].data.shape[0]/n_layers)\n",
    "        ds_pial = nib.load(os.path.join(subj_surf_dir, 'pial.ds.gii'))\n",
    "        layer_fnames = get_surface_names(\n",
    "            n_layers, \n",
    "            subj_surf_dir, \n",
    "            'link_vector.fixed'\n",
    "        )\n",
    "\n",
    "        nas, lpa, rpa = get_fiducial_coords(subject, subjects_file)\n",
    "\n",
    "        orig_data_file=f'pmcspm_converted_autoreject-{subject}-{session}-motor-epo.mat'\n",
    "        data_base = os.path.splitext(orig_data_file)[0]\n",
    "\n",
    "        # Copy data files to tmp directory\n",
    "        shutil.copy(\n",
    "            os.path.join(data_dir, f'{data_base}.mat'),\n",
    "            os.path.join(out_dir, f'{data_base}.mat')\n",
    "        )\n",
    "        shutil.copy(\n",
    "            os.path.join(data_dir, f'{data_base}.dat'),\n",
    "            os.path.join(out_dir, f'{data_base}.dat')\n",
    "        )\n",
    "\n",
    "        # Construct base file name for simulations\n",
    "        base_fname = os.path.join(out_dir, f'{data_base}.mat')\n",
    "\n",
    "        # Coregister data to multilayer mesh\n",
    "        coregister(\n",
    "            nas,\n",
    "            lpa,\n",
    "            rpa,\n",
    "            mri_fname,\n",
    "            multilayer_mesh_fname,\n",
    "            base_fname,\n",
    "            spm_instance=spm,\n",
    "            viz=True\n",
    "        )\n",
    "\n",
    "        # Run localizer on multilayer mesh on -250 to 250ms time window\n",
    "        [_, _, MU] = invert_ebb(\n",
    "            multilayer_mesh_fname,\n",
    "            base_fname,\n",
    "            n_layers,\n",
    "            woi=[-250,250],\n",
    "            patch_size=5,\n",
    "            n_temp_modes=4,\n",
    "            return_mu_matrix=True,\n",
    "            spm_instance=spm,\n",
    "            viz=True\n",
    "        )\n",
    "\n",
    "        # Get left precentral vertices\n",
    "        roi_idx = get_roi_idx(subject, subj_surf_dir, 'lh', ['precentral'], ds_pial)            \n",
    "        \n",
    "        # Find max variance in -100 to 25ms time window in the middle surface layer\n",
    "        all_layer_ts, time, _ = load_source_time_series(\n",
    "            base_fname,\n",
    "            mu_matrix=MU,\n",
    "            vertices=(5-1)*verts_per_surf+np.arange(verts_per_surf)\n",
    "        )        \n",
    "        t_idx=np.where((time>=-.1) & (time<=0.025))[0]\n",
    "        #signal_mag=np.max(np.abs(all_layer_ts[:,t_idx]),axis=-1)\n",
    "        signal_mag=np.var(all_layer_ts[:,t_idx],axis=-1)\n",
    "        \n",
    "        # Compute anatomical predictors\n",
    "        thickness = get_cortical_thickness(multilayer_mesh, n_layers)\n",
    "        gainmat_fname = os.path.join(out_dir, f'SPMgainmatrix_{data_base}_1.mat')\n",
    "        lf_rmse = get_lead_field_rmse(gainmat_fname, n_layers, verts_per_surf)\n",
    "        scalp_mesh_fname = os.path.join(preproc_data_dir,subject,'t1wscalp_2562.surf.gii')\n",
    "        orientations = get_orientation(scalp_mesh_fname, multilayer_mesh, ds_pial, verts_per_surf)\n",
    "        distances = get_dist_to_scalp(scalp_mesh_fname, ds_pial)\n",
    "        \n",
    "        # Z-score each anatomical predictor (note: invert distance to scalp)\n",
    "        z_thickness = zscore(thickness)\n",
    "        z_lf_rmse = zscore(lf_rmse)\n",
    "        z_orient = zscore(orientations)\n",
    "        z_inv_dist = zscore(-distances)\n",
    "\n",
    "        # Composite anatomical score\n",
    "        anatomical_score = z_thickness + z_lf_rmse + z_orient + z_inv_dist\n",
    "\n",
    "        # Restrict to roi_idx\n",
    "        roi_anat_score = anatomical_score[roi_idx]\n",
    "        roi_signal = signal_mag[roi_idx]\n",
    "\n",
    "        # Select top 1% signal vertices within ROI\n",
    "        signal_threshold = np.percentile(roi_signal, 99)\n",
    "        high_signal_mask = roi_signal >= signal_threshold\n",
    "        candidate_indices = roi_idx[high_signal_mask]\n",
    "\n",
    "        # Among them, select the vertex with the best anatomical suitability\n",
    "        candidate_anat_scores = anatomical_score[candidate_indices]\n",
    "        best_idx_local = np.argmax(candidate_anat_scores)\n",
    "        prior = candidate_indices[best_idx_local]\n",
    "\n",
    "        # Get source time series from middle surface layer\n",
    "        prior_ts=all_layer_ts[prior,:]\n",
    "        \n",
    "        # Run sliding time window model comparison\n",
    "        [Fs, wois] = sliding_window_model_comparison(\n",
    "            prior,\n",
    "            nas,\n",
    "            lpa,\n",
    "            rpa,\n",
    "            mri_fname,\n",
    "            layer_fnames,\n",
    "            base_fname,\n",
    "            spm_instance=spm,\n",
    "            viz=False,\n",
    "            invert_kwargs={\n",
    "                'patch_size': 5,\n",
    "                'n_temp_modes': 4,\n",
    "                'win_size': 25,\n",
    "                'win_overlap': True\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Save results\n",
    "        np.savez(\n",
    "            out_fname,\n",
    "            subject=subject,\n",
    "            session=session,\n",
    "            epoch='motor_epoch',\n",
    "            prior=prior,\n",
    "            prior_ts=prior_ts,\n",
    "            ts_time=time * 1000,\n",
    "            Fs=Fs,        \n",
    "            wois=wois\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d5e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lameg_test",
   "language": "python",
   "name": "lameg_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
